{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ab92b4d",
   "metadata": {},
   "source": [
    "## Connect to your GDrive \n",
    "In order to train the network on your data, create a directory named `data/`\n",
    "in the current working directory (cwd) of this notebook (when on colab and connected to gdrive\n",
    "this would be the `MyDrive/` directory in your gdrive account) and put audio files in it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')\n",
    "# this set the cwd of the notebook\n",
    "%cd /gdrive/MyDrive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed3a3f0",
   "metadata": {},
   "source": [
    "### Install `mimikit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9438f0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip uninstall torchtext -y\n",
    "%pip install torch==1.13.1+cu116 torchvision==0.14.1+cu116 torchaudio==0.13.1 --extra-index-url https://download.pytorch.org/whl/cu116\n",
    "%pip install mimikit[colab]==0.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244fa3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab crashes if following import is done within mimikit\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c167ca9",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea88a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5mapper as h5m\n",
    "import mimikit as mmk\n",
    "from pbind import Pseq, Pbind, Pwhite, inf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2089ad1b",
   "metadata": {},
   "source": [
    "### Get some checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f5231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = './'\n",
    "checkpoints = {}\n",
    "for i, path in enumerate(h5m.FileWalker(mmk.CHECKPOINT_REGEX, ROOT_DIR)):\n",
    "    checkpoints[i] = mmk.Checkpoint.from_path(path)\n",
    "checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ab5a8c",
   "metadata": {},
   "source": [
    "### Get the prompts from which to generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af52a14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = checkpoints[0].dataset\n",
    "\n",
    "OUTPUT_SR = 22050\n",
    "PROMPTS_POS_SEC = (\n",
    "    0, OUTPUT_SR // 2, OUTPUT_SR\n",
    ")\n",
    "PROMPT_LENGTH_SEC = OUTPUT_SR\n",
    "\n",
    "# get a batch of prompts\n",
    "prompts = next(iter(db.serve(\n",
    "    (h5m.Input(data='signal', getter=h5m.AsSlice(shift=0, length=PROMPT_LENGTH_SEC)),),\n",
    "    shuffle=False,\n",
    "    # batch_size=1 --> new stream for each prompt <> batch_size=8 --> one stream for 8 prompts :\n",
    "    batch_size=len(PROMPTS_POS_SEC),\n",
    "    sampler=mmk.IndicesSampler(\n",
    "        # INDICES FOR THE PROMPTS :\n",
    "        indices=PROMPTS_POS_SEC\n",
    "    ))))[0]\n",
    "prompts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8986f4dd",
   "metadata": {},
   "source": [
    "### Define a pattern of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1e80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THE MODELS PATTERN defines which checkpoint (id, epoch) generates for how long (seconds)\n",
    "\n",
    "stream = Pseq([\n",
    "    Pbind(\n",
    "        \"generator\", checkpoints[0],\n",
    "        \"seconds\", Pwhite(lo=3., hi=5., repeats=1)\n",
    "    ),\n",
    "    # Pbind(\n",
    "    #     # TODO: This event inserts the most similar continuation from the Trainset \"Cough\"\n",
    "    #     \"seconds\", Pwhite(lo=2., hi=5., repeats=1)\n",
    "    # ),\n",
    "    Pbind(\n",
    "        \"generator\", checkpoints[1],\n",
    "        # SampleRNN Checkpoints work best with a temperature parameter :\n",
    "        \"temperature\", Pwhite(lo=.25, hi=1.5),\n",
    "        \"seconds\", Pwhite(lo=.1, hi=1., repeats=1),\n",
    "    )\n",
    "], inf).asStream()\n",
    "stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc0a206",
   "metadata": {},
   "source": [
    "### Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b5cc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_SECONDS = 10.\n",
    "\n",
    "ensemble = mmk.EnsembleGenerator(\n",
    "    prompts, TOTAL_SECONDS, OUTPUT_SR, stream,\n",
    "    # with this you can print the event -- or not\n",
    "    print_events=False\n",
    ")\n",
    "outputs = ensemble.run()\n",
    "logger = mmk.AudioLogger(sr=OUTPUT_SR)\n",
    "logger.display_batch(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53580683",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb068f",
   "metadata": {},
   "source": [
    "<img src=\"https://ktonal.com/k-circle-bw.png\" alt=\"logo\" width=\"75\"/>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
